\documentclass{nime-alternate}

\begin{document}
%\conferenceinfo{NIME'11,}{30 May--1 June 2011, Oslo, Norway.}

\title{Peacock III: The development of an autonomous non-haptic performance instrument}
\numberofauthors{1}
\author{
\alignauthor
Chikashi Miyama\\
       \affaddr{College of Music and Dance Cologne}\\
       \email{me@chikashi.net}
}

\maketitle
\begin{abstract}
PeacockIII is a box-shaped instrument for musical performances. The instrumemnt is equipped with thirty-five proximity sensors arranged in five rows and seven columns. The sensors detect the movements of a performer's hands and arms in a three-dimensional space above them. In the box, a newly designed PCB collect the output of the sensors  digitizes them into sets of high precision digital packets, and sends them to a small embedded computer placed next to the PCB. An openFramework-based application, running on the computer analyzes the data, detects the gestures and produces sound based on the it.  
\end{abstract}

\keywords{non-haptic, stand alone, infrared sensors, gesture recognition}

\section{Background}

The first model of Peacock, Peacock I,  was developed by the author in 2009\cite{miyama:peacock}. However, through the multiple performances with the interface, several points of improvements were discovoerd. Firstly, the range of infrared sensors is too short (max. 80 cm). Secondly, the band width of the data transfer from the microcontroller to the host computer is not sufficient and it produces latency, that is recognisable from the audience. Thirdly, since the interface should be connected to a host computer by a USB cable, a laptop computer should be always placed next to the interface, and it may disturb the stage appearance.

In 2011, this project received a DAAD research scholarship and a new version of Peacock was realized at ZKM, Karlsruhe, Germany. Peacock II, the new version of Peocock, overcame all the above mentioned issues by employing alternative infrared sensors, faster microcontroller, and Xbee RF modules for wireless data transfer.

\begin{figure}[h]
       \centering
       \includegraphics[width=1\columnwidth]{peacocks}
       \caption{Peacock I and II}
       \label{fig:old_peacock}
\end{figure}

\section{Peacock III}

Peacock II is a significant improvement. However, it still requires an external computer for producing sound. 
In order to improve the autonomy of the instrument, in the newest model of Peacock, Peacock III, a computer for the audio synthesis is embedded in the enclosure of the hardware. Furthermore, the newest model features hardware stabilization of the signal, a basic gesture recognition system, and an improved visualizer. In order to realize these features and facilitate the duplication of the device, a PCB (printed circuit board) is developed for Peacock III.

\section{system overview} % (fold)

The box-shaped Peacock hardware consists of two parts;\bf{interface board} and \bf{main unit}.
The interface board is 100mm x 60mm-sized PCB(printed circuit board). it mainly collect the data from all sensors, digitize them and forward it to the main unit. The main unit analyze the incoming data from the interface board and generates sound. optionally, the main unit visualize the incoming data.

\begin{figure}[htbp]
       \centering
              \includegraphics[width=1\columnwidth]{interface_main}
       \caption{interface board and main unit}
       \label{fig:interface_main}
\end{figure}

\section{Interface Board} % (fold)

The interface board is comprised of a Atmel AVR microcontroller, ATMega 32U2 and five external 12 bit ADCs, MCP3208, a LCD, 5 buttons and a LED. The main functionalities of the interface board are as follows:

\begin{enumerate}
       \item stabilization of the sensor power supply, employing onboard capacitors.
       \item data collection from the sensors and buttons, employing 5 external ADCs
       \item status indication of the peacock, using a LCD
       \item production of data packet 
       \item transfer of the data packets to the main computer via a USB cable, employing LUFA framework
\end{enumerate}

\begin{figure}[htbp]
       \centering
              \includegraphics[width=1\columnwidth]{board}
       \caption{The PCB of Peacock III}
       \label{fig:board}
\end{figure}


\begin{figure}[htbp]
       \centering
              \includegraphics[width=1\columnwidth]{Peacock_hardware}
       \caption{The Peacock III Hardware}
       \label{fig:peacock}
\end{figure}


\subsubsection{Hardware signal stabilization} % (fold)

The signal from infrared sensors employed by Peacock include significant amount of noise. In Peacock I and II, the stabilisation of the signal took place in the software by applying digital low pass filters to all incoming signals, though the hardware level low pass filter is more preferable. On the PCB board of Peacock III, 35 SMD capcitors were employed for the  hardware-level stabilization of each incoming sigal.

\subsubsection{data collection} % (fold)

-SPI 
-speed

\subsubsection{Status indication/manipulation} % (fold)

A 2x16 LCD is attached on the side panel of the enclosure and it displays current status of the system. Users are able to change the setting of the system, and control the program for the sound generation, using this LCD and the buttons, placed next to the LCD.

\subsubsection{Production of safe data packet} % (fold)

A data packet always start with a start delimiter(0xFF), followed by a data type specifier, main data, and ended with a check sum. 

\subsection{transfer of the data packets} % (fold)

In Peacock I, a FTDI chip bridges the UART messages from the AVR microcontroller to the host computer.
However, by employing AVR ATMega 32U2, a microcontroller with a hardware USB controller, the newer version of Peacock is capable of sending data directly from the microcontroller to the host computer. For the development of the USB firmware, the LUFA (Lightweight USB Framework for AVRs)\cite{camera:lufa} was employed. The host computer recognize the Peacock PCB as a virtual serial device.

\section{Main Unit} % (fold)
A dedicated Intel NUC computer, ultra Compact Form factor computer with intel Corei5 processor placed next to the PCB board in the enclosure, runs Arch linux and automatically launch the PeacockApp, an OpenFrameworks\cite{openframeworks}-based application written in C++. This application receives the data from the microcontroller and send it to the following three modules. The gesture recognizer module analyze the incoming data and detects specific hand gesture, The synthesizer module is for sound production, and the visualizer module visualizes the incoming data.

\begin{enumerate}
       \item Gesture Recognizer(PckRecognizer)
       \item Synthesizer(PckSynthesizer)
       \item Visualizer(PckVisualizer)
\end{enumerate}

The Gesture Recognizer analyzes the incoming data, analyzes it with numerous different techniques and send a notification to the other two modules when it detect a new hand gesture\ref{fig:modules}.


\begin{figure}[htbp]
       \centering
              \includegraphics[width=1\columnwidth]{Peacock_app}
       \caption{The Peacock III App}
       \label{fig:modules}
\end{figure}

In order to minimize the latency and maximize the efficiency of the data processing, These three modules runs onthree separate threads in the application. If the Gesture Recognizer module detects a certain hand gesture, a notification will be sent immediately to the other two modules.


\subsection{Gesture Recognizer: PckRecognizer}

\subsubsection{Lower Level Analysis}

\begin{enumerate}
       \item Centroid X,Y
       \item Hand position
\end{enumerate}


\subsubsection{Higher Level Analysis}

\begin{enumerate}
       \item Centroid X,Y
       \item Hand position
\end{enumerate}

\subsection{Sound Generator: PckSynthesizer}

The sound generator modulede is programmed with an addOn 
 is written with Pd(Pure Data) and integrated to the PeacockApp; an Add-on of OpenFrameworks, ofxPd, loads the Pd patch and runs it within the process of the application.

\subsection{Visualizer: PckVisualizer}

Unlike piano, cello, or other acoustic instruments, the player of Peacock controls musical parameters by simply moving hand above the device; There is no physical feedback from the instrument. In order to improve accurate parameter control, pricise positioning and movements of the hands is necessary. For this end, a visualizer provides the performer with optical feedback.  The visualizer indicates the values of from 35 infrared sensors  the assumed position of hands, chronological trail of hand movement, and recognized gestures, in  3D model programmed with OpenGL. The renderered 3D images can be displayed by attaching an optional HDMI-compatible monitor to the device.
The visualizer can be deactivated by the user by the buttons on the side of the enclosure.


\section{evaluation}

\subsection{bandwidth}
The system is capable of capture the values from all sensors more than 1000 time per second.



\section{future works}

- Further improvement of firmware and in the gesture recognition module is expected.
The source code of the PeacockApp and Peacock Firmware is hosted on github.com under GPL v3 lincense.


\section{acknowledgement}
This project is funded by fellowship program of the Academy of Media Arts Cologne. The author would like to express my sincere appreciation to Prof. Anthony Moore and Mr. Dirk Specht for their valuable support.

\bibliographystyle{abbrv}
\bibliography{KHM-references.bib}
\subsection{References}
\texttt{{\char'134}thebibliography}

\end{document}
